#streamlit run Bible_story.py
#ì‹¤í–‰ streamlit run Lagnchain_with_bible_250329.py --server.address=0.0.0.0 --server.port=8501
import streamlit as st

from langchain.schema.runnable import RunnableMap
from langchain.retrievers.multi_query import MultiQueryRetriever

#import google.generativeai as genai
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_community.document_loaders import TextLoader
from langchain_core.prompts import PromptTemplate

import os
import re

from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.embeddings import Embeddings

from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.retrievers import BM25Retriever  #TF-IDF ê³„ì—´ì˜ ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜
from langchain.retrievers import EnsembleRetriever # ì—¬ëŸ¬ retrieverë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ ì²˜ë¦¬
from langchain_community.vectorstores.faiss import DistanceStrategy #vectorstoresì˜ ê±°ë¦¬ ê³„ì‚°
from langchain.memory import ConversationBufferWindowMemory

import pickle
import time


from google import genai
from google.genai import types
from io import BytesIO
from PIL import Image
import PIL

from gtts import gTTS
import edge_tts
import io
import wave
from sentence_transformers import SentenceTransformer

def get_conversation_chain(vectorstore,data_list,query,st_memory):
   
    #llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-thinking-exp-01-21", temperature=0)
    #llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-thinking-exp", temperature=0)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash-preview-05-20", temperature=0)

    template = """ë‹¹ì‹ ì€ ì¸ê³µì§€ëŠ¥ ChatBOTìœ¼ë¡œ Question ë‚´ìš©ì— ëŒ€í•´ì„œ ëŒ€ë‹µí•©ë‹ˆë‹¤.
    Contextì— ìˆëŠ” ë‚´ìš©ì„ ì°¸ì¡°í•´ì„œë§Œ ëŒ€ë‹µí•©ë‹ˆë‹¤.
    ëŒ€ë‹µì€ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.
    ëŒ€ë‹µì€ contextì˜ ìˆëŠ” original sourceë„ ê°™ì´ ì¶œë ¥í•©ë‹ˆë‹¤.
    #Chat history: 
    {chat_history}
    #Context: 
    {context}
    #Question:
    {question}

    #Answer:
    """

    prompt = ChatPromptTemplate.from_template(template)

    faiss_retriever=vectorstore.as_retriever(search_type="mmr",
    search_kwargs={'k':10, 'fetch_k': 30})

    # initialize the bm25 retriever(10ê°œ)
    bm25_retriever = BM25Retriever.from_documents(data_list)
    bm25_retriever.k = 10

    f_ratio = 0.7
    # initialize the ensemble retriever
    #retriever ê°€ì¤‘ì¹˜ ì„¤ì •(bm25:30% + faiss:70%)
    # ë¬¸ì„œ ê²°í•© ë°©ì‹ ì„¤ì •(default setting:combine_documents-ê²°í•©ëœ ë¬¸ì„œë“¤ì„ í•©ì¹˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë™ì‘)
    ensemble_retriever_combine = EnsembleRetriever(
        retrievers=[bm25_retriever, faiss_retriever], weights=[1-f_ratio, f_ratio] 
        ,retriever_type="combine_documents")
    
    multiqueryretriever = MultiQueryRetriever.from_llm(ensemble_retriever_combine, llm=llm)


    memory = st_memory

    chain = (
      RunnableMap({
        "context": lambda x: multiqueryretriever.invoke(x['question']),
        "question": lambda x: x['question'],
        'chat_history' : lambda x: x['chat_history']
    }) 
    | prompt | llm | StrOutputParser())

    full_response = '' 
    for chunk in chain.stream({'question': query,
                            'chat_history': memory.load_memory_variables({})['chat_history']}):
        full_response += chunk


    return full_response

def make_story(response,name="í¬ë¦¬ìŠ¤"):
   
    #llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-thinking-exp-01-21", temperature=0)
    #llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-thinking-exp", temperature=0)
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.5-flash-preview-04-17-thinking", temperature=0.5)

    template = """"ë‹¹ì‹ ì€ ì„¸ê³„ ìµœê³ ì˜ ì• ë‹ˆë©”ì´ì…˜ ë™í™”ì±… ì‘ê°€ì…ë‹ˆë‹¤.
    Contextë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì´ì•¼ê¸°ë¥¼ ë§Œë“¤ê³  ë‹¤ìŒ ê·œì¹™ì„ ì§€ì¼œì„œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

    [ê·œì¹™]
    1. Contextì˜ ë‚´ìš©ì€ ì„±ê²½ì˜ ë‚´ìš©ì„ ìš”ì•½í•œ ê²ƒì…ë‹ˆë‹¤.        
    2. Context ì „ì²´ ë‚´ìš©ì„ íŒŒì•…í•˜ê³  ë™í™” ì´ì•¼ê¸° ì£¼ì œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.  
    3. ë™í™”ëŠ” {name}ì´ë¼ëŠ” ì•„ì´ê°€ ì• ë‹ˆë©”ì´ì…˜ ìŠˆí¼ë¶ì²˜ëŸ¼ ìŠˆí¼ë¶ì´ë¼ëŠ” íƒ€ì„ë¨¸ì‹ ì„ íƒ€ê³  ì„±ê²½ ì† ì¥ë©´ì„ ì—¿ë³´ëŠ” í˜•íƒœë¡œ ë§Œë“­ë‹ˆë‹¤.
    4. ë™í™”ëŠ” ì „ì²´ ì´ì•¼ê¸°ë¥¼ ì‚¬ê±´ê³¼ ì¥ë©´ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì±•í„°ë¡œ ë‚˜ëˆ„ì–´ì„œ ì„¸ë¶€ ë‚´ìš©ì„ ìƒì„±í•©ë‹ˆë‹¤.
    5. ë™í™”ëŠ” ì´ì•¼ê¸°ë¥¼ ë“£ëŠ” ì‚¬ëŒì´ ë¯¸ì·¨í•™ ì–´ë¦°ì´ë¶€í„° ì´ˆë“±í•™êµ 3í•™ë…„ ì´í•˜ ìˆ˜ì¤€ìœ¼ë¡œ ì‰½ê³  ì¬ë¯¸ìˆê²Œ ì‘ì„±í•©ë‹ˆë‹¤.
    6. ìì—°ìŠ¤ëŸ¬ìš´ ì´ì•¼ê¸°ê¸°ë¥¼ ìœ„í•´ ëŒ€í™”ì²´ë¥¼ í¬í•¨í•˜ë„ë¡ í•©ë‹ˆë‹¤.
    7. ê° ì±•í„°ì— ì–´ìš¸ë¦¬ëŠ” ë™í™” ì¼ëŸ¬ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•œ ì´ë¯¸ì§€ promptë¥¼ ë§Œë“­ë‹ˆë‹¤. promptëŠ” <image> í‚¤ì›Œë“œë¡œ ë¶„ë¦¬ ìƒì„±í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ promptëŠ” ë¬¸ì¥ ì‚¬ì´ì— ë„ì–´ ì“°ê¸°ë¥¼ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. promptëŠ” ì±•í„°ë§ˆë‹¤ 1ê°œë§Œ ìƒì„±í•©ë‹ˆë‹¤.
    8. ë™í™” ì´ì•¼ê¸°ì˜ ì¤„ê±°ë¦¬ëŠ” <summary> í‚¤ì›Œë“œë¡œ ë¶„ë¦¬ ìƒì„±í•©ë‹ˆë‹¤.

    #Context: 
    {context}

    #Answer:
    """

    prompt = ChatPromptTemplate.from_template(template)

    chain = (prompt | llm | StrOutputParser())

    #response = chain.invoke({'question': query,
    #                         'chat_history': memory.load_memory_variables({})['chat_history']})
    
    #story_message_placeholder = st.empty() # DeltaGenerator ë°˜í™˜
    
    full_response = '' 
    for chunk in chain.stream({"context": response,
                               "name": name}):
        full_response += chunk
        #story_message_placeholder.markdown(full_response)

    return full_response

def print_story(story):
    st.session_state.story_list = story.split('\n')

    full_tts_response = ''

    for i in range(len(st.session_state.story_list)):
        if "<summary>" in st.session_state.story_list[i]:
            st.session_state.story_summary = st.session_state.story_list[i]

    for i in range(len(st.session_state.story_list)):
        if ("<image>" in st.session_state.story_list[i]) or ("</image>" in st.session_state.story_list[i]) or ("<summary>" in st.session_state.story_list[i]) or ("</summary>" in st.session_state.story_list[i]):
            if ("<image>" in st.session_state.story_list[i]) or ("</image>" in st.session_state.story_list[i]):
                if st.session_state.image_option == 'ì´ë¯¸ì§€ ìƒì„±':
                    try:
                        image = make_image3(st.session_state.story_list[i],
                                           st.session_state.story_summary)

                        if image: # ì´ë¯¸ì§€ ìƒì„±ì´ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸
                            st.image(image)
                            time.sleep(6) #gemini api limit
                            st.session_state.full_story_list.append(image) 
                        else:
                            # ì„ íƒ ì‚¬í•­: ì´ ë¶€ë¶„ì— ëŒ€í•œ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ ì•Œë¦¼
                            # st.markdown("_ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤._")
                            pass
                    except Exception as e:
                        # st.error(f"ì´ë¯¸ì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}") # ë””ë²„ê¹…ìš©
                        continue
            else:
                continue
        else:
            st.markdown(st.session_state.story_list[i])
            st.session_state.full_story_list.append(st.session_state.story_list[i])  
            full_tts_response += st.session_state.story_list[i]
            time.sleep(0.1)

    return full_tts_response

def make_image(response,summary):
    # API í‚¤ ì„¤ì •
    client = genai.Client(api_key=st.session_state.gemini_api_key)

    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-exp-image-generation", temperature=0.3)
    #llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-preview-image-generation", temperature=0.3)

    prompt_template = PromptTemplate(
        template="""
        The section content is a story from the Bible. Based on the following section content, create a prompt to generate a Ghibli Studio-style image to represent this section. Your prompt should be less than 500 characters. Be consistent in your image creation and refer to the Summary for full details. Write your prompt in English. 
        
        Section content:
        
        {section_content}

        Summary:
        
        {summary}
        
        Prompt:""",
        input_variables=["section_content", "summary"],
    )
    
    image_prompt = llm.invoke(prompt_template.format(section_content=response, summary=summary))

    contents = image_prompt.content

    # Gemini 2.0 Flash Experimental ëª¨ë¸ ì‚¬ìš©
    response = client.models.generate_content(
        model="models/gemini-2.0-flash-exp",
        #model="gemini-2.0-flash-preview-image-generation",
        contents=contents,
        config=types.GenerateContentConfig(
            response_modalities=['Text', 'Image'],
            temperature=0.7,
        )
    )

    # ì‘ë‹µ ì²˜ë¦¬
    for part in response.candidates[0].content.parts:
        try:
            if part.inline_data is not None:
                image_bytes = part.inline_data.data
                image = Image.open(BytesIO(part.inline_data.data))
                return image
        
        except Exception as e:
            continue
    


def make_image2(response,summary):
    # API í‚¤ ì„¤ì •
    client = genai.Client(api_key=st.session_state.gemini_api_key)

    llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-exp-image-generation", temperature=0.3)
    #llm = ChatGoogleGenerativeAI(model="gemini-2.0-flash-preview-image-generation", temperature=0.3)

    prompt_template = PromptTemplate(
        template="""
        The section content is a story from the Bible. Based on the following section content, create a prompt to generate a japanese fairy tale animation style image to represent this section. Your prompt should be less than 500 characters. Be consistent in your image creation and refer to the Summary for full details. Write your prompt in English. 
        
        Section content:
        
        {section_content}

        Summary:
        
        {summary}
        
        Prompt:""",
        input_variables=["section_content", "summary"],
    )
    
    image_prompt = llm.invoke(prompt_template.format(section_content=response, summary=summary))

    contents = image_prompt.content

    # Gemini 2.0 Flash Experimental ëª¨ë¸ ì‚¬ìš©
    response = client.models.generate_content(
        model="models/gemini-2.0-flash-exp",
        #model="gemini-2.0-flash-preview-image-generation",
        contents=contents,
        config=types.GenerateContentConfig(
            response_modalities=['Text', 'Image'],
            temperature=0.7,
        )
    )

    # ì‘ë‹µ ì²˜ë¦¬
    for part in response.candidates[0].content.parts:
        if part.inline_data is not None:
            image_bytes = part.inline_data.data
            image = Image.open(BytesIO(part.inline_data.data))
            st.image(image)

def make_image3(response,summary):
    # API í‚¤ ì„¤ì •
    client = genai.Client(api_key=st.session_state.gemini_api_key)

    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash-preview-05-20", temperature=0.3)

    prompt_template = PromptTemplate(
        template="""
        The section content is a story from the Bible. Based on the following section content, create a prompt to generate a Ghibli Studio-style image to represent this section. Your prompt should be less than 500 characters. Be consistent in your image creation and refer to the Summary for full details. Write your prompt in English. 
        
        Section content:
        
        {section_content}

        Summary:
        
        {summary}
        
        Prompt:""",
        input_variables=["section_content", "summary"],
    )
    
    image_prompt = llm.invoke(prompt_template.format(section_content=response, summary=summary))

    contents = image_prompt.content

    response = client.models.generate_content(
        model="gemini-2.0-flash-preview-image-generation",
        contents=contents,
        config=types.GenerateContentConfig(
        response_modalities=['TEXT', 'IMAGE']))

    # ì‘ë‹µ ì²˜ë¦¬
    for part in response.candidates[0].content.parts:
        try:
            if part.inline_data is not None:
                image_bytes = part.inline_data.data
                image = Image.open(BytesIO(part.inline_data.data))
                return image
        
        except Exception as e:
            continue

def print_response(response):

    #ì‹¤ì‹œê°„ ì¶œë ¥(Stream)

    sentence = ''
    
    if '\n' not in response:
        st.write(response)

    else: 
        for chunk in response:
            #st.write(chunk)
            if chunk in ['\n','\n\n', '\n\n\n']:
                st.write(sentence)
                time.sleep(0.1)
                sentence = ''
            else:
                sentence = sentence + chunk

def handle_userinput(user_question):
    response = st.session_state.conversation({'question': user_question})
    st.session_state.chat_history = response['chat_history']

    for i, message in enumerate(st.session_state.chat_history):
        if i % 2 == 0:
            st.write(f"Human: {message.content}")
        else:
            st.write(f"AI: {message.content}")

# ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜
def get_chat_history_str(chat_history):
    return "\n".join([f"{entry['role'].capitalize()}: {entry['content']}" for entry in chat_history])

def file_read():
    folder_path = "C:\\python\\Bible-Rag\\new_data"
    file_list = os.listdir(folder_path)

    documents = []
    pattern2 = r'[ê°€-í£]+'

    for file_name in file_list:
        loader = TextLoader(folder_path+'\\'+file_name, encoding='utf-8')
        document = loader.load()
        result2 = re.search(pattern2, file_name)
        if result2:
            book_name = result2.group()
        document[0].metadata = {'source':book_name}
        documents.append(document)

    document_list = []
    for index,i in enumerate(documents):
        document_list.append(i[0])

    return document_list

def text_splitter(document_list):
    # 2000ì(overlap=50ë¡œ ì²­í‚¹í•˜ê¸°
    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 3000,chunk_overlap = 50)
    #splitterë¥¼ ì´ìš©í•œ ë¬¸ì„œ ì²­í‚¹
    data = text_splitter.split_documents(document_list)

    return data

def make_vectorstore(data):

    #ì„ë² ë”© ëª¨ë¸
    embeddings = HuggingFaceEmbeddings(model_name='jhgan/ko-sroberta-multitask')

    vectorstore = FAISS.from_documents(documents=data, embedding=embeddings)

    st.success(f"ì´ {len(data)}ê°œì˜ í˜ì´ì§€ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    
    return vectorstore

class GeminiEmbeddings(Embeddings):
    def __init__(self, api_key, model="gemini-embedding-exp-03-07", task_type="SEMANTIC_SIMILARITY"):
        self.client = genai.Client(api_key=api_key)
        self.model = model
        self.task_type = task_type
    
    def embed_documents(self, texts):
        embeddings = []
        for text in texts:
            result = self.client.models.embed_content(
                model=self.model,
                contents=text,
                config=types.EmbedContentConfig(task_type=self.task_type)
            )
            embeddings.append(result.embeddings[0].values)
        return embeddings
    
    def embed_query(self, text):
        result = self.client.models.embed_content(
            model=self.model,
            contents=text,
            config=types.EmbedContentConfig(task_type=self.task_type)
        )
        return result.embeddings[0].values

def load_bible():
    with st.spinner("íŒŒì¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
        
        #ì„ë² ë”© ëª¨ë¸ ë¶ˆë¡œì˜¤ê¸°
        #embeddings = SentenceTransformer('jhgan/ko-sroberta-multitask')
        embeddings = GeminiEmbeddings(api_key=st.session_state.gemini_api_key)

        # ì €ì¥ëœ ì¸ë±ìŠ¤ ë¡œë“œ(allow_dangerous_deserialization=True í•„ìš”)
        
        vectorstore = FAISS.load_local("Rag_data/bible_embed_gemini", 
        embeddings,
        distance_strategy=DistanceStrategy.EUCLIDEAN_DISTANCE, 
        allow_dangerous_deserialization=True)

        with open("Rag_data/bible_data2.pkl", 'rb') as f:
            data_load = pickle.load(f)
    
    st.success(f"ì´ {len(data_load)}ê°œì˜ í˜ì´ì§€ë¥¼ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    return data_load, vectorstore

def text_to_speech(text, language='ko'):

    text_new = re.sub('[^a-zA-Zê°€-í£0-9.,:()?!]', ' ', text)

    # gTTSë¡œ í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
    tts = gTTS(text=text_new, lang=language)
    
    # ë©”ëª¨ë¦¬ì— ì˜¤ë””ì˜¤ ì €ì¥
    audio_data = io.BytesIO()
    tts.write_to_fp(audio_data)
    audio_data.seek(0)

    # ì˜¤ë””ì˜¤ ì¬ìƒ
    st.audio(audio_data, format="audio/mp3")

    #audio_dataë¥¼ historyì— ì €ì¥
    st.session_state.full_story_list.append({'mp3':audio_data})
    
    # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
    st.download_button(
        label="ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
        data=audio_data,
        file_name="output.mp3",
        mime="audio/mp3"
    )

def text_to_speech2(text, voice_option):

    text_new = re.sub('[^a-zA-Zê°€-í£0-9.,:()?!]', ' ', text)

    if voice_option == 'ì—¬ì„±':
        voice = "ko-KR-SunHiNeural" #ì—¬ì„±

    elif voice_option == 'ë‚¨ì„±2':
        voice = "ko-KR-InJoonNeural" #ë‚¨ì„±2

    else:
        voice = "ko-KR-HyunsuNeural" #ë‚¨ì„±3

    # ìŒì„± ìƒì„±
    tts = edge_tts.Communicate(text_new, voice)

    # ë©”ëª¨ë¦¬ì— ì˜¤ë””ì˜¤ ì €ì¥
    tts.save_sync('output.mp3')

    with open("output.mp3", "rb") as f:
        audio_data = f.read()
    
    st.audio(audio_data, format="audio/mp3")

    #audio_dataë¥¼ historyì— ì €ì¥
    st.session_state.full_story_list.append({'mp3':audio_data})
    
    st.download_button(
        label="ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
        data=audio_data,
        file_name="output.mp3",
        mime="audio/mp3"
    )

def text_to_speech3(text):

    text_new = re.sub('[^a-zA-Zê°€-í£0-9.,:()?!]', ' ', text)

    # ìŒì„± ë©”ì‹œì§€ ë¶„í• (2000ì ì´ë‚´)

    #strings = text_new.splitlines() # ë¬¸ìì—´ì„ ê°œí–‰ë¬¸ì(\n)ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ ë¬¸ìì—´ë¡œ ë‚˜ëˆˆ list
    strings = text_new.split(".") # ë¬¸ìì—´ì„ .ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì—¬ëŸ¬ ê°œì˜ ë¬¸ìì—´ë¡œ ë‚˜ëˆˆ list

    new_string = []
    for s in strings:
        if len(s) > 0:                         # ê³µë°± ë¬¸ì ì œê±°
            new_string.append(s.strip() + ".") # ê³µë°± ë¬¸ì ì œê±° ë° ë¬¸ìì—´ ëì— . ì¶”ê°€

    MAX_LENGTH = 2000                           # Max ë¬¸ì ì„¤ì • : 2000ì
    text_list = []
    long_string = ''
    for s in new_string:
        if len(long_string) + len(s) > MAX_LENGTH:
            text_list.append(long_string)
            long_string = s
        else:
            long_string = long_string.strip() + ' ' + s.strip()
    if long_string:
        text_list.append(long_string)

    wave_list = []

    # API í‚¤ ì„¤ì •
    client = genai.Client(api_key=st.session_state.gemini_api_key)

    # ê°ì •ì´ ë‹´ê¸´ í•œêµ­ì–´ í”„ë¡¬í”„íŠ¸
    for index,text in enumerate(text_list):
        emotional_prompt = f"""ë‹¤ìŒì€ ì–´ë¦°ì´ ì„±ê²½ ë™í™”ì…ë‹ˆë‹¤. ì‹¤ê°ë‚˜ê²Œ ë§í•´ ì£¼ì„¸ìš”.:
        {text}"""
        response = client.models.generate_content(
            model="gemini-2.5-flash-preview-tts",
            contents=emotional_prompt,
            config=types.GenerateContentConfig(
                response_modalities=["AUDIO"],
                speech_config=types.SpeechConfig(
                    voice_config=types.VoiceConfig(
                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                            voice_name='Kore'  )
                        )
                    )
                )
            )

        try:
            # ì‘ë‹µì—ì„œ ìŒì„± ë°ì´í„° ì¶”ì¶œ ë° ì €ì¥
            if response.candidates and response.candidates[0].content.parts:
                audio_data = response.candidates[0].content.parts[0].inline_data.data

            #ìŒì„± ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥
            with wave.open(f"output{index}.wav", 'wb') as wav_file:
                wav_file.setnchannels(1)  # ëª¨ë…¸
                wav_file.setsampwidth(2)  # 16ë¹„íŠ¸
                wav_file.setframerate(24000)  # 24kHz ìƒ˜í”Œë§ ë ˆì´íŠ¸
                wav_file.writeframes(audio_data)

            wave_list.append(f"output{index}.wav")

        except Exception as e:
            st.info("ìŒì„± íŒŒì¼ ìƒì„±ì„ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ìŒì„± ëª¨ë¸ì„ ì‚¬ìš©í•´ ë³´ì„¸ìš”.")

    outfile = "output.wav"

    # ì²« íŒŒì¼ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
    with wave.open(wave_list[0], 'rb') as w:
        params = w.getparams()

    output = wave.open(outfile, 'wb')
    output.setparams(params)

    for infile in wave_list:
        with wave.open(infile, 'rb') as w:
            output.writeframes(w.readframes(w.getnframes()))

    output.close()

    with open("output.wav", "rb") as f:
        audio_data = f.read()
        
    st.audio(audio_data, format='audio/wav')

    #audio_dataë¥¼ historyì— ì €ì¥
    st.session_state.full_story_list.append({'wav':audio_data})

    st.download_button(
        label="ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
        data=audio_data,
        file_name="output.wav",
        mime="audio/wav"
    )

def main():

    st.set_page_config(page_title="Lagnchain_with_bible", page_icon="ğŸ“–")
    st.title("ğŸ“– ì„±ê²½ ë™í™” ë§Œë“¤ê¸°")

    if "conversation" not in st.session_state:
        st.session_state.conversation = None
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    if "vectorstore" not in st.session_state:
        st.session_state.vectorstore = None
    if "document_list" not in st.session_state:
        st.session_state.document_list = []
    if "vector_option" not in st.session_state:
        st.session_state.vector_option = None
    if "gemini_api_key" not in st.session_state:
        st.session_state.gemini_api_key = None
    if "response" not in st.session_state:
        st.session_state.response = None
    if "voice_option" not in st.session_state:
        st.session_state.voice_option = None
    if "image_option" not in st.session_state:
        st.session_state.image_option = None
    if "story" not in st.session_state:
        st.session_state.story = None
    if "story_list" not in st.session_state:
        st.session_state.story_list = []
    if "tts_story" not in st.session_state:
        st.session_state.tts_story = None
    if "story_summary" not in st.session_state:
        st.session_state.story_summary = None
    if "name" not in st.session_state:
        st.session_state.name = None
    if "full_story_list" not in st.session_state:
        st.session_state.full_story_list = []
    if "user_query" not in st.session_state:
        st.session_state.user_query = None

    #ìœˆë„ìš° í¬ê¸° kë¥¼ ì§€ì •í•˜ë©´ ìµœê·¼ kê°œì˜ ëŒ€í™”ë§Œ ê¸°ì–µí•˜ê³  ì´ì „ ëŒ€í™”ëŠ” ì‚­ì œ
    if "memory" not in st.session_state:
        st.session_state.memory = ConversationBufferWindowMemory(memory_key="chat_history", k=4,return_messages=True) 

    with st.sidebar:
        st.session_state.gemini_api_key = st.text_input('Gemini_API_KEYë¥¼ ì…ë ¥í•˜ì„¸ìš”.', key="langchain_search_api_gemini", type="password")
        "[Gemini API Key ë§Œë“¤ê¸°](https://aistudio.google.com/apikey)"
        "[Gemini API Key ë§Œë“œëŠ” ë°©ë²•(ì„¤ëª…)](https://booknbeyondinsights.tistory.com/entry/gemini-api-key-guide)"

        if (st.session_state.gemini_api_key[0:2] != 'AI') or (len(st.session_state.gemini_api_key) != 39):
            st.warning('ì˜ëª»ëœ key ì…ë ¥', icon='âš ï¸')
        else:
            st.success('ì •ìƒ key ì…ë ¥', icon='ğŸ‘‰')

        if process :=st.button("Process"):
            if (st.session_state.gemini_api_key[0:2] != 'AI') or (len(st.session_state.gemini_api_key) != 39):
                st.error("ì˜ëª»ëœ key ì…ë ¥ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
                st.stop()

        if data_clear :=st.button("ëŒ€í™” í´ë¦¬ì–´"):
            st.session_state.conversation = None
            st.session_state.chat_history = []
            st.session_state.memory = ConversationBufferWindowMemory(memory_key="chat_history", k=4,return_messages=True)
            st.session_state.response = None
            st.session_state.story = None
            st.session_state.story_list = []
            st.session_state.tts_story = None
            st.session_state.story_summary = None
            st.session_state.full_story_list = []
            st.session_state.user_query = None 
            st.rerun() # ì´ˆê¸°í™”ëœ ìƒíƒœë¥¼ ì¦‰ì‹œ ë°˜ì˜í•˜ê¸° ìœ„í•´

        st.session_state.name = st.text_input("ì´ë¦„", value="", placeholder="ì•„ì´ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”.")

        st.session_state.voice_option = st.radio(label='ìŒì„± ìƒì„± ê¸°ëŠ¥',
                          options=['ìœ ì¹˜ì›ì„ ìƒë‹˜','ì—¬ì„±','ë‚¨ì„±1','ë‚¨ì„±2','ë‚¨ì„±3', 'ìŒì„± ë¯¸ìƒì„±'],
                          index=0  # ê¸°ë³¸ ì„ íƒê°’ì€ ì—¬ì„±
                          )
        
        st.session_state.image_option = st.radio(label='ì´ë¯¸ì§€ ìƒì„± ê¸°ëŠ¥',
                          options=['ì´ë¯¸ì§€ ìƒì„±', 'ì´ë¯¸ì§€ ë¯¸ìƒì„±'],
                          index=0  # ê¸°ë³¸ ì„ íƒê°’ì€ ìƒì„±
                          )
            
    #0. gemini api key Setting
    if not st.session_state.gemini_api_key:
        st.warning("Gemini API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”.")
        st.stop()

    #genai.configure(api_key=gemini_api_key)

    #0. gemini api key Setting
    os.environ["GOOGLE_API_KEY"] = st.session_state.gemini_api_key


    # íŒŒì¼ì´ ì—…ë¡œë“œë˜ë©´ ì²˜ë¦¬
    if st.session_state.vectorstore == None:

        st.session_state.document_list, st.session_state.vectorstore = load_bible()

    st.chat_message("assistant").write("ì•ˆë…•í•˜ì„¸ìš”. ë¬´ì—‡ì„ ë„ì™€ë“œë¦´ê¹Œìš”?")

    #2. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì¶œë ¥
    # st.session_state['chat_history']ê°€ ìˆìœ¼ë©´ ì‹¤í–‰
    
    #if ("chat_history" in st.session_state) and (len(st.session_state['chat_history'])>0):
    #    #st.session_state['messages']ëŠ” tuple í˜•íƒœë¡œ ì €ì¥ë˜ì–´ ìˆìŒ.
    #    for role, message in st.session_state['chat_history']:
    #        if role == 'user':
    #            st.chat_message(role).write(message)
    #        elif role == 'assistant':
    #            with st.chat_message(role):
    #                for content in message:
    #                    if type(content) == str:
    #                        st.markdown(content)
    #                    elif type(content) == PIL.Image.Image:
    #                        st.write("[Image]")
    #                        st.image(content)

    #2. ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì¶œë ¥
    if "chat_history" in st.session_state and st.session_state.chat_history:
        for role, message_content in st.session_state.chat_history:
            if role == 'user':
                st.chat_message(role).write(message_content) # ì‚¬ìš©ìì˜ ê²½ìš°, message_contentëŠ” ì§ˆì˜ ë¬¸ìì—´
            elif role == 'assistant':
                with st.chat_message(role):
                    # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ê²½ìš°, message_contentëŠ” ë¬¸ìì—´ ë°/ë˜ëŠ” PIL.Image.Image ê°ì²´ì˜ ë¦¬ìŠ¤íŠ¸ì—¬ì•¼ í•¨
                    if isinstance(message_content, list):
                        for item in message_content:
                            if isinstance(item, str):
                                st.markdown(item)
                            elif isinstance(item, PIL.Image.Image):
                                st.image(item) # ì´ì œ ì´ë¯¸ì§€ê°€ í‘œì‹œë˜ì–´ì•¼ í•©ë‹ˆë‹¤
                            elif isinstance(item, dict):
                                index = 0
                                if 'wav' in item:
                                    audio_data = item.get('wav')
                                    st.audio(audio_data, format='audio/wav')
                                    st.download_button(
                                        label="ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
                                        data=audio_data,
                                        file_name="output.wav",
                                        mime="audio/wav")
                                elif 'mp3' in item:
                                    audio_data = item.get('mp3')
                                    st.audio(audio_data, format='audio/mp3')
                                    st.download_button(
                                        label="ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ",
                                        data=audio_data,
                                        file_name="output.mp3",
                                        mime="audio/mp3")
                    else:
                        # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ê°€ ë‹¨ì¼ ë¬¸ìì—´ì¸ ê²½ìš° (ì˜ˆ: ì˜¤ë¥˜ ë©”ì‹œì§€ ë˜ëŠ” ì´ì „ í˜•ì‹)
                        st.markdown(str(message_content))

    #3. queryë¥¼ ì…ë ¥ë°›ëŠ”ë‹¤.
    #st.session_state.user_query = st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.", key="input_box")
#
    ##3.5 queryê°€ ì—†ì„ ë•Œ
#
    #questions = [
    #    "ì°½ì„¸ê¸° 1ì¥ ë§ì”€ì„ ì•Œë ¤ì£¼ì„¸ìš”.",
    #    "ì˜ˆìˆ˜ë‹˜ê³¼ ì‚­ê°œì˜¤ê°€ ë§Œë‚œ ì´ì•¼ê¸°ë¥¼ í•´ ì£¼ì„¸ìš”.", 
    #    "ì„±ë ¹ì˜ ì—´ë§¤ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.",
    #    "ì‹œí¸ 41ì¥ 1ì ˆë¶€í„° 13ì ˆ ë§ì”€ì„ ì•Œë ¤ì£¼ì„¸ìš”."]
#
    #if not st.session_state.user_query:
    #    sample = st.selectbox("ë˜ëŠ” ì˜ˆì‹œ ì§ˆë¬¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”:", questions, key="sample_box")
    #    query = sample
    #else:
    #    query = st.session_state.user_query
 
    #3. queryë¥¼ ì…ë ¥ë°›ëŠ”ë‹¤.
    if query := st.chat_input("ë§ì”€ ì£¼ì œë‚˜ ì•Œê³  ì‹¶ì€ ì„±ê²½ êµ¬ì ˆì„ ì•Œë ¤ì£¼ì„¸ìš”. \n ex1)ì°½ì„¸ê¸° 1ì¥ì„ ì•Œë ¤ì£¼ì„¸ìš”. \n ex2)ì˜ˆìˆ˜ë‹˜ê³¼ ì‚­ê°œì˜¤ê°€ ë§Œë‚œ ì´ì•¼ê¸°ë¥¼ í•´ ì£¼ì„¸ìš”.", key="input_box"):
        #4.'user' iconìœ¼ë¡œ queryë¥¼ ì¶œë ¥í•œë‹¤.
        st.chat_message("user").write(query)
        #5. queryë¥¼ session_state 'user'ì— append í•œë‹¤.
        st.session_state['chat_history'].append(('user',query))

        with st.chat_message("assistant"):
            with st.spinner("Thinking..."):
                start_time = time.time()
                # chain í˜¸ì¶œ
                st.session_state.response = get_conversation_chain(
                    st.session_state.vectorstore,
                    st.session_state.document_list,
                    query,
                    st.session_state.memory)

                #story ë§Œë“¤ê¸°
                st.session_state.story = make_story(st.session_state.response,
                                                    st.session_state.name)
                
                # ì¤‘ìš”: í˜„ì¬ ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ë¥¼ ìœ„í•´ full_story_list ì´ˆê¸°í™”
                st.session_state.full_story_list = []

                #story ì¶œë ¥í•˜ê¸°    
                st.session_state.tts_story = print_story(st.session_state.story)
                #ë‹µë³€ ìŒì„± ìƒì„±í•˜ê¸°
                with st.spinner("ìŒì„± íŒŒì¼ ìƒì„± ì¤‘ì…ë‹ˆë‹¤."):
                    if st.session_state.voice_option == 'ìœ ì¹˜ì›ì„ ìƒë‹˜':
                        text_to_speech3(text=st.session_state.tts_story)
                    elif len(st.session_state.tts_story) > 5000:
                        st.warning('ë‹µë³€ ê¸¸ì´ê°€ ë„ˆë¬´ ê¸¸ì–´ì„œ ìŒì„± íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
                    elif st.session_state.voice_option == 'ë‚¨ì„±1':
                        text_to_speech(text=st.session_state.tts_story,language='ko')
                    elif st.session_state.voice_option != 'ìŒì„± ë¯¸ìƒì„±':
                        text_to_speech2(text=st.session_state.tts_story,
                                        voice_option=st.session_state.voice_option)
                end_time = time.time()
                total_time = (end_time - start_time)
                st.info(f"ê²€ìƒ‰ ì†Œìš” ì‹œê°„: {total_time}ì´ˆ")
                if st.session_state.full_story_list != None:
                    st.session_state['chat_history'].append(
                        ('assistant',st.session_state.full_story_list))
    
    else:
        #st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        pass

if __name__ == '__main__':
    main()